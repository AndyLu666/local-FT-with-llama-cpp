#include <iostream>
#include <vector>
#include <random>
#include <cmath>
#include <algorithm>
#include <iomanip>
#include <memory>
#include <cstring>

// ä½¿ç”¨ggmlçš„å¤šå±‚ç¥ç»ç½‘ç»œ
class GGMLMultiLayerNet {
private:
    struct ggml_context* ctx_;
    
    // ç½‘ç»œå±‚å‚æ•°
    struct ggml_tensor* W1_;  // ç¬¬ä¸€å±‚æƒé‡ [hidden_size, input_size]
    struct ggml_tensor* b1_;  // ç¬¬ä¸€å±‚åç½® [hidden_size]
    struct ggml_tensor* W2_;  // ç¬¬äºŒå±‚æƒé‡ [output_size, hidden_size]  
    struct ggml_tensor* b2_;  // ç¬¬äºŒå±‚åç½® [output_size]
    
    int input_size_;
    int hidden_size_;
    int output_size_;
    float learning_rate_;
    
public:
    GGMLMultiLayerNet(int input_size, int hidden_size, int output_size, float learning_rate = 0.01f)
        : input_size_(input_size), hidden_size_(hidden_size), output_size_(output_size), learning_rate_(learning_rate) {
        
        // åˆå§‹åŒ–ggmlä¸Šä¸‹æ–‡
        struct ggml_init_params params = {
            .mem_size = 128 * 1024 * 1024,  // 128MBå†…å­˜
            .mem_buffer = NULL,
            .no_alloc = false,
        };
        
        ctx_ = ggml_init(params);
        if (!ctx_) {
            throw std::runtime_error("æ— æ³•åˆå§‹åŒ–ggmlä¸Šä¸‹æ–‡");
        }
        
        // åˆ›å»ºç½‘ç»œå±‚å¼ é‡
        W1_ = ggml_new_tensor_2d(ctx_, GGML_TYPE_F32, input_size_, hidden_size_);
        b1_ = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, hidden_size_);
        W2_ = ggml_new_tensor_2d(ctx_, GGML_TYPE_F32, hidden_size_, output_size_);
        b2_ = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, output_size_);
        
        // è®¾ç½®ä¸ºå¯è®­ç»ƒå‚æ•°
        ggml_set_param(W1_);
        ggml_set_param(b1_);
        ggml_set_param(W2_);
        ggml_set_param(b2_);
        
        // åˆå§‹åŒ–æƒé‡
        init_weights();
        
        std::cout << "ğŸš€ GGMLå¤šå±‚ç¥ç»ç½‘ç»œå·²åˆ›å»ºï¼" << std::endl;
        std::cout << "ğŸ“Š ç½‘ç»œæ¶æ„ï¼š" << input_size_ << " â†’ " << hidden_size_ << " â†’ " << output_size_ << std::endl;
        std::cout << "âš™ï¸  æ¿€æ´»å‡½æ•°ï¼šReLU â†’ Softmax" << std::endl;
        std::cout << "ğŸ¯ å¯è®­ç»ƒå‚æ•°ï¼š" << get_param_count() << " ä¸ª" << std::endl;
    }
    
    ~GGMLMultiLayerNet() {
        if (ctx_) {
            ggml_free(ctx_);
        }
    }
    
    void init_weights() {
        std::mt19937 rng(42);
        std::normal_distribution<float> dist(0.0f, 0.1f);
        
        // åˆå§‹åŒ–ç¬¬ä¸€å±‚æƒé‡å’Œåç½®
        float* w1_data = ggml_get_data_f32(W1_);
        for (int i = 0; i < ggml_nelements(W1_); ++i) {
            w1_data[i] = dist(rng);
        }
        
        float* b1_data = ggml_get_data_f32(b1_);
        for (int i = 0; i < ggml_nelements(b1_); ++i) {
            b1_data[i] = 0.0f;
        }
        
        // åˆå§‹åŒ–ç¬¬äºŒå±‚æƒé‡å’Œåç½®
        float* w2_data = ggml_get_data_f32(W2_);
        for (int i = 0; i < ggml_nelements(W2_); ++i) {
            w2_data[i] = dist(rng);
        }
        
        float* b2_data = ggml_get_data_f32(b2_);
        for (int i = 0; i < ggml_nelements(b2_); ++i) {
            b2_data[i] = 0.0f;
        }
        
        std::cout << "ğŸ² æƒé‡å·²éšæœºåˆå§‹åŒ–" << std::endl;
    }
    
    // å¤šå±‚å‰å‘ä¼ æ’­ï¼šä½¿ç”¨ggmlå†…ç½®å‡½æ•°é“¾å¼æ„å»º
    struct ggml_tensor* forward(struct ggml_tensor* input) {
        // ç¬¬ä¸€å±‚ï¼šçº¿æ€§å˜æ¢ + ReLUæ¿€æ´»
        struct ggml_tensor* z1 = ggml_mul_mat(ctx_, W1_, input);  // W1 * input
        z1 = ggml_add(ctx_, z1, b1_);                             // + b1
        struct ggml_tensor* a1 = ggml_relu(ctx_, z1);             // ReLUæ¿€æ´»
        
        // ç¬¬äºŒå±‚ï¼šçº¿æ€§å˜æ¢ + Softmaxæ¿€æ´»  
        struct ggml_tensor* z2 = ggml_mul_mat(ctx_, W2_, a1);     // W2 * a1
        z2 = ggml_add(ctx_, z2, b2_);                             // + b2
        struct ggml_tensor* output = ggml_soft_max(ctx_, z2);     // Softmaxæ¿€æ´»
        
        return output;
    }
    
    // è®¡ç®—äº¤å‰ç†µæŸå¤±ï¼šä½¿ç”¨ggmlå†…ç½®æŸå¤±å‡½æ•°
    struct ggml_tensor* compute_loss(struct ggml_tensor* logits, struct ggml_tensor* targets) {
        // ä½¿ç”¨ggmlå†…ç½®çš„äº¤å‰ç†µæŸå¤±å‡½æ•°
        return ggml_cross_entropy_loss(ctx_, logits, targets);
    }
    
    // è®­ç»ƒæ­¥éª¤ï¼šå±•ç¤ºggmlçš„è‡ªåŠ¨å¾®åˆ†èƒ½åŠ›
    void train_step(const std::vector<float>& input_data, const std::vector<float>& target_data) {
        // åˆ›å»ºè¾“å…¥å¼ é‡
        struct ggml_tensor* input = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, input_size_);
        float* input_ptr = ggml_get_data_f32(input);
        std::memcpy(input_ptr, input_data.data(), input_size_ * sizeof(float));
        
        // åˆ›å»ºç›®æ ‡å¼ é‡
        struct ggml_tensor* target = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, output_size_);
        float* target_ptr = ggml_get_data_f32(target);
        std::memcpy(target_ptr, target_data.data(), output_size_ * sizeof(float));
        
        // å‰å‘ä¼ æ’­
        struct ggml_tensor* prediction = forward(input);
        
        // è®¡ç®—æŸå¤±
        struct ggml_tensor* loss = compute_loss(prediction, target);
        ggml_set_loss(loss);
        
        // åˆ›å»ºè®¡ç®—å›¾ï¼ˆæ”¯æŒè‡ªåŠ¨å¾®åˆ†ï¼‰
        struct ggml_cgraph* graph = ggml_new_graph_custom(ctx_, 1024, true);
        ggml_build_forward_expand(graph, loss);
        
        // æ„å»ºåå‘ä¼ æ’­å›¾ï¼ˆè‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼ï¼‰
        ggml_build_backward_expand(ctx_, graph, nullptr);
        
        // è¿™é‡Œå±•ç¤ºäº†ggmlçš„è®¡ç®—å›¾ç»“æ„
        std::cout << "ğŸ“ˆ è®¡ç®—å›¾å·²æ„å»ºï¼ŒåŒ…å« " << ggml_graph_n_nodes(graph) << " ä¸ªèŠ‚ç‚¹" << std::endl;
        
        // æ³¨æ„ï¼šå®Œæ•´çš„è®­ç»ƒéœ€è¦backendæ¥æ‰§è¡Œè®¡ç®—å’Œæ¢¯åº¦æ›´æ–°
        // è¿™é‡Œä¸»è¦å±•ç¤ºggmlå¯ä»¥æ„å»ºä»»æ„å¤æ‚çš„å¤šå±‚ç½‘ç»œç»“æ„
    }
    
    int get_param_count() const {
        return ggml_nelements(W1_) + ggml_nelements(b1_) + 
               ggml_nelements(W2_) + ggml_nelements(b2_);
    }
    
    void print_architecture() {
        std::cout << "\nğŸ—ï¸  ç½‘ç»œæ¶æ„è¯¦æƒ…ï¼š" << std::endl;
        std::cout << "   è¾“å…¥å±‚: " << input_size_ << " ä¸ªç¥ç»å…ƒ" << std::endl;
        std::cout << "   éšè—å±‚: " << hidden_size_ << " ä¸ªç¥ç»å…ƒ (ReLUæ¿€æ´»)" << std::endl;
        std::cout << "   è¾“å‡ºå±‚: " << output_size_ << " ä¸ªç¥ç»å…ƒ (Softmaxæ¿€æ´»)" << std::endl;
        std::cout << "   æ€»å‚æ•°: " << get_param_count() << " ä¸ª" << std::endl;
        
        std::cout << "\nâš¡ GGMLå†…ç½®å‡½æ•°ä½¿ç”¨ï¼š" << std::endl;
        std::cout << "   âœ… ggml_mul_mat()   - çŸ©é˜µä¹˜æ³•" << std::endl;
        std::cout << "   âœ… ggml_add()       - çŸ©é˜µåŠ æ³•" << std::endl;
        std::cout << "   âœ… ggml_relu()      - ReLUæ¿€æ´»å‡½æ•°" << std::endl;
        std::cout << "   âœ… ggml_soft_max()  - Softmaxæ¿€æ´»å‡½æ•°" << std::endl;
        std::cout << "   âœ… ggml_cross_entropy_loss() - äº¤å‰ç†µæŸå¤±å‡½æ•°" << std::endl;
        std::cout << "   âœ… ggml_build_backward_expand() - è‡ªåŠ¨å¾®åˆ†" << std::endl;
    }
};

int main() {
    std::cout << "ğŸ§  GGMLå¤šå±‚ç¥ç»ç½‘ç»œæ¼”ç¤º\n" << std::endl;
    std::cout << "=========================================" << std::endl;
    
    try {
        // åˆ›å»ºä¸€ä¸ª4-16-3çš„å¤šå±‚ç½‘ç»œ
        GGMLMultiLayerNet network(4, 16, 3, 0.01f);
        network.print_architecture();
        
        // æ¼”ç¤ºè®­ç»ƒæ­¥éª¤
        std::cout << "\nğŸ¯ æ¼”ç¤ºè®­ç»ƒè¿‡ç¨‹..." << std::endl;
        
        std::vector<float> input = {0.5f, -0.2f, 0.8f, -0.1f};
        std::vector<float> target = {0.0f, 1.0f, 0.0f};  // one-hotç¼–ç 
        
        std::cout << "ğŸ“ è¾“å…¥æ•°æ®: [" << input[0] << ", " << input[1] 
                  << ", " << input[2] << ", " << input[3] << "]" << std::endl;
        std::cout << "ğŸ“ ç›®æ ‡è¾“å‡º: [" << target[0] << ", " << target[1] 
                  << ", " << target[2] << "]" << std::endl;
        
        network.train_step(input, target);
        
        std::cout << "\nğŸ’¡ å…³é”®ç‚¹è§£é‡Šï¼š" << std::endl;
        std::cout << "   ğŸ”¹ GGMLå®Œå…¨æ”¯æŒå¤šå±‚ç¥ç»ç½‘ç»œï¼" << std::endl;
        std::cout << "   ğŸ”¹ å¯ä»¥é“¾å¼è°ƒç”¨å¤šä¸ªggmlå‡½æ•°æ„å»ºå¤æ‚ç½‘ç»œ" << std::endl;
        std::cout << "   ğŸ”¹ æ”¯æŒå„ç§æ¿€æ´»å‡½æ•°ï¼šReLU, Sigmoid, Tanh, GELUç­‰" << std::endl;
        std::cout << "   ğŸ”¹ å†…ç½®è‡ªåŠ¨å¾®åˆ†ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—æ¢¯åº¦" << std::endl;
        std::cout << "   ğŸ”¹ æ”¯æŒä»»æ„æ·±åº¦çš„ç½‘ç»œç»“æ„" << std::endl;
        
        std::cout << "\nğŸ¤” é‚£ä¸ºä»€ä¹ˆEnhanced-MLPä¸ç”¨ggmlï¼Ÿ" << std::endl;
        std::cout << "   ç­”æ¡ˆï¼šè¿™åªæ˜¯æ¼”ç¤ºé€‰æ‹©ï¼Enhanced-MLPä¸»è¦å±•ç¤º" << std::endl;
        std::cout << "   è½¯ä»¶æ¶æ„è®¾è®¡ï¼Œè€Œä¸æ˜¯æ€§èƒ½ä¼˜åŒ–ã€‚" << std::endl;
        std::cout << "   å¦‚æœè¦è¿½æ±‚æ€§èƒ½ï¼Œå®Œå…¨å¯ä»¥ç”¨ggmlé‡å†™Enhanced-MLPï¼" << std::endl;
        
        std::cout << "\nâœ… æ¼”ç¤ºå®Œæˆï¼GGMLçš„å¼ºå¤§åŠŸèƒ½å±•ç¤ºæ— é—ï¼" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ é”™è¯¯ï¼š" << e.what() << std::endl;
        return 1;
    }
    
    return 0;
} 