#include "../src/simple-neural-model.h"
#include <iostream>
#include <vector>
#include <random>
#include <chrono>

// ç”Ÿæˆåˆæˆæ•¸æ“šé›†
void generate_synthetic_data(std::vector<std::vector<float>>& inputs, 
                           std::vector<int>& labels, 
                           int num_samples = 1000) {
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<float> dist(-2.0f, 2.0f);
    
    inputs.resize(num_samples);
    labels.resize(num_samples);
    
    for (int i = 0; i < num_samples; ++i) {
        inputs[i].resize(4);
        for (int j = 0; j < 4; ++j) {
            inputs[i][j] = dist(gen);
        }
        
        // ç°¡å–®çš„åˆ†é¡è¦å‰‡
        float sum = inputs[i][0] + inputs[i][1] + inputs[i][2] + inputs[i][3];
        if (sum < -2.0f) {
            labels[i] = 0;
        } else if (sum > 2.0f) {
            labels[i] = 2;
        } else {
            labels[i] = 1;
        }
    }
}

// è¨ˆç®—æº–ç¢ºç‡
float calculate_accuracy(const std::vector<std::vector<float>>& predictions,
                        const std::vector<int>& labels) {
    int correct = 0;
    for (size_t i = 0; i < predictions.size(); ++i) {
        int predicted_class = 0;
        float max_prob = predictions[i][0];
        for (size_t j = 1; j < predictions[i].size(); ++j) {
            if (predictions[i][j] > max_prob) {
                max_prob = predictions[i][j];
                predicted_class = j;
            }
        }
        if (predicted_class == labels[i]) {
            correct++;
        }
    }
    return static_cast<float>(correct) / predictions.size() * 100.0f;
}

int main(int argc, char* argv[]) {
    std::cout << "=== GPUç¥ç¶“ç¶²è·¯è¨“ç·´æ¼”ç¤º ===" << std::endl;
    
    // è§£æå‘½ä»¤è¡Œåƒæ•¸
    bool use_gpu = false;
    std::string backend_type = "auto";
    int gpu_device = 0;
    
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        if (arg == "--gpu") {
            use_gpu = true;
        } else if (arg == "--backend" && i + 1 < argc) {
            backend_type = argv[++i];
        } else if (arg == "--device" && i + 1 < argc) {
            gpu_device = std::stoi(argv[++i]);
        } else if (arg == "--help" || arg == "-h") {
            std::cout << "ç”¨æ³•: " << argv[0] << " [é¸é …]" << std::endl;
            std::cout << "é¸é …:" << std::endl;
            std::cout << "  --gpu              ä½¿ç”¨GPUåŠ é€Ÿ" << std::endl;
            std::cout << "  --backend TYPE     æŒ‡å®šå¾Œç«¯é¡å‹ (auto, cpu, cuda, metal)" << std::endl;
            std::cout << "  --device ID        æŒ‡å®šGPUè¨­å‚™ID (é»˜èª: 0)" << std::endl;
            std::cout << "  --help, -h         é¡¯ç¤ºæ­¤å¹«åŠ©ä¿¡æ¯" << std::endl;
            return 0;
        }
    }
    
    try {
        // é…ç½®æ¨¡å‹åƒæ•¸
        SimpleNeuralModel::ModelParams params;
        params.input_size = 4;
        params.hidden_size = 16;
        params.output_size = 3;
        params.use_gpu = use_gpu;
        params.backend_type = backend_type;
        params.gpu_device = gpu_device;
        
        std::cout << "\nğŸ“‹ æ¨¡å‹é…ç½®:" << std::endl;
        std::cout << "  è¼¸å…¥ç¶­åº¦: " << params.input_size << std::endl;
        std::cout << "  éš±è—ç¶­åº¦: " << params.hidden_size << std::endl;
        std::cout << "  è¼¸å‡ºç¶­åº¦: " << params.output_size << std::endl;
        std::cout << "  ä½¿ç”¨GPU: " << (use_gpu ? "æ˜¯" : "å¦") << std::endl;
        std::cout << "  å¾Œç«¯é¡å‹: " << backend_type << std::endl;
        if (use_gpu) {
            std::cout << "  GPUè¨­å‚™: " << gpu_device << std::endl;
        }
        
        // å‰µå»ºæ¨¡å‹
        std::cout << "\nğŸš€ åˆå§‹åŒ–æ¨¡å‹..." << std::endl;
        auto start_init = std::chrono::high_resolution_clock::now();
        
        SimpleNeuralModel model(params);
        
        auto end_init = std::chrono::high_resolution_clock::now();
        auto init_time = std::chrono::duration_cast<std::chrono::milliseconds>(end_init - start_init);
        
        std::cout << "âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (" << init_time.count() << "ms)" << std::endl;
        std::cout << "ğŸ–¥ï¸  ä½¿ç”¨å¾Œç«¯: " << model.get_backend_name() << std::endl;
        std::cout << "ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨: " << model.get_memory_usage() / 1024.0 / 1024.0 << " MB" << std::endl;
        
        // ç”Ÿæˆè¨“ç·´æ•¸æ“š
        std::cout << "\nğŸ“Š ç”Ÿæˆåˆæˆæ•¸æ“šé›†..." << std::endl;
        std::vector<std::vector<float>> train_inputs, test_inputs;
        std::vector<int> train_labels, test_labels;
        
        generate_synthetic_data(train_inputs, train_labels, 800);
        generate_synthetic_data(test_inputs, test_labels, 200);
        
        std::cout << "  è¨“ç·´æ¨£æœ¬: " << train_inputs.size() << std::endl;
        std::cout << "  æ¸¬è©¦æ¨£æœ¬: " << test_inputs.size() << std::endl;
        
        // æ¸¬è©¦å‰å‘å‚³æ’­æ€§èƒ½
        std::cout << "\nâš¡ æ€§èƒ½æ¸¬è©¦..." << std::endl;
        
        // å–®æ¨£æœ¬å‰å‘å‚³æ’­
        auto start_single = std::chrono::high_resolution_clock::now();
        auto single_result = model.forward(train_inputs[0]);
        auto end_single = std::chrono::high_resolution_clock::now();
        auto single_time = std::chrono::duration_cast<std::chrono::microseconds>(end_single - start_single);
        
        std::cout << "  å–®æ¨£æœ¬å‰å‘å‚³æ’­: " << single_time.count() << " Î¼s" << std::endl;
        
        // æ‰¹é‡å‰å‘å‚³æ’­
        auto start_batch = std::chrono::high_resolution_clock::now();
        auto batch_results = model.forward_batch(test_inputs);
        auto end_batch = std::chrono::high_resolution_clock::now();
        auto batch_time = std::chrono::duration_cast<std::chrono::milliseconds>(end_batch - start_batch);
        
        std::cout << "  æ‰¹é‡å‰å‘å‚³æ’­ (" << test_inputs.size() << " æ¨£æœ¬): " << batch_time.count() << " ms" << std::endl;
        std::cout << "  å¹³å‡æ¯æ¨£æœ¬: " << static_cast<float>(batch_time.count()) / test_inputs.size() << " ms" << std::endl;
        
        // è¨ˆç®—åˆå§‹æº–ç¢ºç‡
        float initial_accuracy = calculate_accuracy(batch_results, test_labels);
        std::cout << "\nğŸ“ˆ åˆå§‹æ¸¬è©¦æº–ç¢ºç‡: " << initial_accuracy << "%" << std::endl;
        
        // è¨ˆç®—æå¤±
        float initial_loss = model.compute_loss(batch_results, test_labels);
        std::cout << "ğŸ“‰ åˆå§‹æ¸¬è©¦æå¤±: " << initial_loss << std::endl;
        
        // æ¼”ç¤ºè¨“ç·´æ­¥é©Ÿï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
        std::cout << "\nğŸ¯ æ¼”ç¤ºè¨“ç·´æ­¥é©Ÿ..." << std::endl;
        for (int epoch = 0; epoch < 5; ++epoch) {
            std::cout << "Epoch " << (epoch + 1) << "/5:" << std::endl;
            
            // é€™è£¡åªæ˜¯æ¼”ç¤ºï¼Œå¯¦éš›çš„åå‘å‚³æ’­éœ€è¦æ›´è¤‡é›œçš„å¯¦ç¾
            model.backward_and_update(train_inputs, train_labels, 0.001f);
            
            // æ¸¬è©¦ç•¶å‰æ€§èƒ½
            auto current_predictions = model.forward_batch(test_inputs);
            float current_accuracy = calculate_accuracy(current_predictions, test_labels);
            float current_loss = model.compute_loss(current_predictions, test_labels);
            
            std::cout << "  æº–ç¢ºç‡: " << current_accuracy << "%" << std::endl;
            std::cout << "  æå¤±: " << current_loss << std::endl;
        }
        
        // ä¿å­˜æ¨¡å‹
        std::string model_filename = "gpu_neural_model_" + model.get_backend_name() + ".bin";
        std::cout << "\nğŸ’¾ ä¿å­˜æ¨¡å‹..." << std::endl;
        if (model.save_model(model_filename)) {
            std::cout << "âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: " << model_filename << std::endl;
        }
        
        // æ¸¬è©¦æ¨¡å‹åŠ è¼‰
        std::cout << "\nğŸ”„ æ¸¬è©¦æ¨¡å‹åŠ è¼‰..." << std::endl;
        SimpleNeuralModel loaded_model(params);
        if (loaded_model.load_model(model_filename)) {
            auto loaded_predictions = loaded_model.forward_batch(test_inputs);
            float loaded_accuracy = calculate_accuracy(loaded_predictions, test_labels);
            std::cout << "âœ… åŠ è¼‰æ¨¡å‹çš„æ¸¬è©¦æº–ç¢ºç‡: " << loaded_accuracy << "%" << std::endl;
        }
        
        std::cout << "\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ éŒ¯èª¤: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
} 