#include "ggml/include/ggml.h"
#include "ggml/include/ggml-alloc.h"
#include "ggml/include/ggml-backend.h"
#include "ggml/src/ggml-cpu/ggml-cpu.h"

#include <iostream>
#include <vector>
#include <random>
#include <cmath>
#include <iomanip>

class GGMLMultiLayerLogisticRegression {
private:
    // GGMLä¸Šä¸‹æ–‡
    struct ggml_context* ctx_static;
    struct ggml_context* ctx_compute;
    ggml_backend_t backend;
    ggml_backend_buffer_t buffer;
    
    // ç½‘ç»œç»“æ„
    int input_size;
    int hidden_size;
    int output_size;
    int batch_size;
    
    // ç½‘ç»œå‚æ•°ï¼ˆå¼ é‡ï¼‰
    struct ggml_tensor* W1;  // ç¬¬ä¸€å±‚æƒé‡ [input_size, hidden_size]
    struct ggml_tensor* b1;  // ç¬¬ä¸€å±‚åç½® [hidden_size]
    struct ggml_tensor* W2;  // ç¬¬äºŒå±‚æƒé‡ [hidden_size, output_size]
    struct ggml_tensor* b2;  // ç¬¬äºŒå±‚åç½® [output_size]
    
    // è¾“å…¥è¾“å‡ºå¼ é‡
    struct ggml_tensor* input;   // è¾“å…¥ [batch_size, input_size]
    struct ggml_tensor* target;  // ç›®æ ‡ [batch_size, output_size]
    struct ggml_tensor* output;  // ç½‘ç»œè¾“å‡º
    struct ggml_tensor* loss;    // æŸå¤±
    
    // è®¡ç®—å›¾
    struct ggml_cgraph* forward_graph;
    struct ggml_cgraph* backward_graph;
    
public:
    GGMLMultiLayerLogisticRegression(int input_size, int hidden_size, int output_size, int batch_size = 32)
        : input_size(input_size), hidden_size(hidden_size), output_size(output_size), batch_size(batch_size) {
        
        // åˆå§‹åŒ–CPUåç«¯
        backend = ggml_backend_cpu_init();
        
        // åˆ›å»ºé™æ€ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå‚æ•°ï¼‰
        {
            struct ggml_init_params params = {
                .mem_size = 16 * 1024 * 1024,  // 16MB
                .mem_buffer = nullptr,
                .no_alloc = true,
            };
            ctx_static = ggml_init(params);
        }
        
        // åˆ›å»ºè®¡ç®—ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå‰å‘ä¼ æ’­ï¼‰
        {
            struct ggml_init_params params = {
                .mem_size = 32 * 1024 * 1024,  // 32MB
                .mem_buffer = nullptr,
                .no_alloc = true,
            };
            ctx_compute = ggml_init(params);
        }
        
        // åˆ›å»ºå‚æ•°å¼ é‡
        createParameters();
        
        // åˆ†é…å†…å­˜
        allocateMemory();
        
        // åˆå§‹åŒ–å‚æ•°
        initializeParameters();
        
        // æ„å»ºè®¡ç®—å›¾
        buildComputeGraph();
    }
    
    ~GGMLMultiLayerLogisticRegression() {
        if (buffer) ggml_backend_buffer_free(buffer);
        if (backward_graph) ggml_free(backward_graph->ctx);
        if (ctx_compute) ggml_free(ctx_compute);
        if (ctx_static) ggml_free(ctx_static);
        if (backend) ggml_backend_free(backend);
    }
    
private:
    void createParameters() {
        // ç¬¬ä¸€å±‚æƒé‡å’Œåç½®
        W1 = ggml_new_tensor_2d(ctx_static, GGML_TYPE_F32, input_size, hidden_size);
        b1 = ggml_new_tensor_1d(ctx_static, GGML_TYPE_F32, hidden_size);
        ggml_set_param(W1);  // æ ‡è®°ä¸ºå¯è®­ç»ƒå‚æ•°
        ggml_set_param(b1);
        ggml_set_name(W1, "W1");
        ggml_set_name(b1, "b1");
        
        // ç¬¬äºŒå±‚æƒé‡å’Œåç½®
        W2 = ggml_new_tensor_2d(ctx_static, GGML_TYPE_F32, hidden_size, output_size);
        b2 = ggml_new_tensor_1d(ctx_static, GGML_TYPE_F32, output_size);
        ggml_set_param(W2);  // æ ‡è®°ä¸ºå¯è®­ç»ƒå‚æ•°
        ggml_set_param(b2);
        ggml_set_name(W2, "W2");
        ggml_set_name(b2, "b2");
        
        // è¾“å…¥å’Œç›®æ ‡å¼ é‡
        input = ggml_new_tensor_2d(ctx_static, GGML_TYPE_F32, input_size, batch_size);
        target = ggml_new_tensor_2d(ctx_static, GGML_TYPE_F32, output_size, batch_size);
        ggml_set_name(input, "input");
        ggml_set_name(target, "target");
    }
    
    void allocateMemory() {
        // ä¸ºæ‰€æœ‰å¼ é‡åˆ†é…å†…å­˜
        buffer = ggml_backend_alloc_ctx_tensors(ctx_static, backend);
    }
    
    void initializeParameters() {
        // Xavieråˆå§‹åŒ–æƒé‡
        std::random_device rd;
        std::mt19937 gen(rd());
        
        // åˆå§‹åŒ–W1 (Xavier)
        float w1_scale = std::sqrt(2.0f / (input_size + hidden_size));
        std::normal_distribution<float> w1_dist(0.0f, w1_scale);
        std::vector<float> w1_data(input_size * hidden_size);
        for (auto& w : w1_data) w = w1_dist(gen);
        ggml_backend_tensor_set(W1, w1_data.data(), 0, ggml_nbytes(W1));
        
        // åˆå§‹åŒ–b1ä¸ºé›¶
        std::vector<float> b1_data(hidden_size, 0.0f);
        ggml_backend_tensor_set(b1, b1_data.data(), 0, ggml_nbytes(b1));
        
        // åˆå§‹åŒ–W2 (Xavier)
        float w2_scale = std::sqrt(2.0f / (hidden_size + output_size));
        std::normal_distribution<float> w2_dist(0.0f, w2_scale);
        std::vector<float> w2_data(hidden_size * output_size);
        for (auto& w : w2_data) w = w2_dist(gen);
        ggml_backend_tensor_set(W2, w2_data.data(), 0, ggml_nbytes(W2));
        
        // åˆå§‹åŒ–b2ä¸ºé›¶
        std::vector<float> b2_data(output_size, 0.0f);
        ggml_backend_tensor_set(b2, b2_data.data(), 0, ggml_nbytes(b2));
    }
    
    void buildComputeGraph() {
        // å‰å‘ä¼ æ’­ï¼šä½¿ç”¨çº¯GGMLå†…ç½®å‡½æ•°
        // ç¬¬ä¸€å±‚ï¼šz1 = input * W1 + b1
        struct ggml_tensor* z1 = ggml_add(ctx_compute,
            ggml_mul_mat(ctx_compute, W1, input), 
            ggml_repeat(ctx_compute, b1, ggml_new_tensor_2d(ctx_compute, GGML_TYPE_F32, hidden_size, batch_size))
        );
        
        // ReLUæ¿€æ´»ï¼ša1 = relu(z1)
        struct ggml_tensor* a1 = ggml_unary(ctx_compute, z1, GGML_UNARY_OP_RELU);
        
        // ç¬¬äºŒå±‚ï¼šz2 = a1 * W2 + b2
        struct ggml_tensor* z2 = ggml_add(ctx_compute,
            ggml_mul_mat(ctx_compute, W2, a1),
            ggml_repeat(ctx_compute, b2, ggml_new_tensor_2d(ctx_compute, GGML_TYPE_F32, output_size, batch_size))
        );
        
        // Sigmoidæ¿€æ´»ï¼ˆç”¨äºé€»è¾‘å›å½’ï¼‰ï¼šoutput = sigmoid(z2)
        output = ggml_unary(ctx_compute, z2, GGML_UNARY_OP_SIGMOID);
        ggml_set_name(output, "output");
        
        // äº¤å‰ç†µæŸå¤±ï¼šä½¿ç”¨GGMLå†…ç½®çš„äº¤å‰ç†µæŸå¤±å‡½æ•°
        loss = ggml_cross_entropy_loss(ctx_compute, output, target);
        ggml_set_name(loss, "loss");
        ggml_set_loss(loss);  // æ ‡è®°ä¸ºæŸå¤±å¼ é‡
        
        // æ„å»ºå‰å‘ä¼ æ’­å›¾
        forward_graph = ggml_new_graph_custom(ctx_compute, GGML_DEFAULT_GRAPH_SIZE, false);
        ggml_build_forward_expand(forward_graph, loss);
        
        // æ„å»ºåå‘ä¼ æ’­å›¾ï¼ˆç”¨äºè®­ç»ƒï¼‰
        backward_graph = ggml_new_graph_custom(ctx_compute, GGML_DEFAULT_GRAPH_SIZE, true);
        ggml_build_forward_expand(backward_graph, loss);
        ggml_build_backward_expand(ctx_compute, backward_graph, nullptr);
    }
    
public:
    // å‰å‘ä¼ æ’­
    float forward(const std::vector<std::vector<float>>& X, const std::vector<std::vector<float>>& y) {
        // è®¾ç½®è¾“å…¥æ•°æ®
        std::vector<float> input_data(input_size * batch_size);
        std::vector<float> target_data(output_size * batch_size);
        
        for (int b = 0; b < batch_size; ++b) {
            for (int i = 0; i < input_size; ++i) {
                input_data[b * input_size + i] = X[b][i];
            }
            for (int o = 0; o < output_size; ++o) {
                target_data[b * output_size + o] = y[b][o];
            }
        }
        
        ggml_backend_tensor_set(input, input_data.data(), 0, ggml_nbytes(input));
        ggml_backend_tensor_set(target, target_data.data(), 0, ggml_nbytes(target));
        
        // æ‰§è¡Œå‰å‘ä¼ æ’­
        ggml_backend_graph_compute(backend, forward_graph);
        
        // è·å–æŸå¤±å€¼
        float loss_value;
        ggml_backend_tensor_get(loss, &loss_value, 0, sizeof(float));
        
        return loss_value;
    }
    
    // è®­ç»ƒä¸€æ­¥ï¼ˆå‰å‘+åå‘ä¼ æ’­ï¼‰
    void trainStep(const std::vector<std::vector<float>>& X, const std::vector<std::vector<float>>& y, float learning_rate = 0.01f) {
        // å‰å‘ä¼ æ’­
        forward(X, y);
        
        // åå‘ä¼ æ’­ï¼šGGMLè‡ªåŠ¨è®¡ç®—æ¢¯åº¦
        ggml_backend_graph_compute(backend, backward_graph);
        
        // æ‰‹åŠ¨æ›´æ–°å‚æ•°ï¼ˆç®€å•SGDï¼‰
        updateParameters(learning_rate);
    }
    
    // é¢„æµ‹
    std::vector<std::vector<float>> predict(const std::vector<std::vector<float>>& X) {
        // åˆ›å»ºè™šæ‹Ÿç›®æ ‡ï¼ˆé¢„æµ‹æ—¶ä¸ä½¿ç”¨ï¼‰
        std::vector<std::vector<float>> dummy_y(batch_size, std::vector<float>(output_size, 0.0f));
        
        // å‰å‘ä¼ æ’­
        forward(X, dummy_y);
        
        // è·å–è¾“å‡º
        std::vector<float> output_data(output_size * batch_size);
        ggml_backend_tensor_get(output, output_data.data(), 0, ggml_nbytes(output));
        
        std::vector<std::vector<float>> predictions(batch_size, std::vector<float>(output_size));
        for (int b = 0; b < batch_size; ++b) {
            for (int o = 0; o < output_size; ++o) {
                predictions[b][o] = output_data[b * output_size + o];
            }
        }
        
        return predictions;
    }
    
private:
    void updateParameters(float learning_rate) {
        // è·å–æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°
        updateParameter(W1, learning_rate);
        updateParameter(b1, learning_rate);
        updateParameter(W2, learning_rate);
        updateParameter(b2, learning_rate);
    }
    
    void updateParameter(struct ggml_tensor* param, float learning_rate) {
        // è·å–å‚æ•°çš„æ¢¯åº¦
        struct ggml_tensor* grad = ggml_graph_get_grad(backward_graph, param);
        if (!grad) return;
        
        size_t param_size = ggml_nelements(param);
        std::vector<float> param_data(param_size);
        std::vector<float> grad_data(param_size);
        
        // è·å–å½“å‰å‚æ•°å€¼å’Œæ¢¯åº¦
        ggml_backend_tensor_get(param, param_data.data(), 0, ggml_nbytes(param));
        ggml_backend_tensor_get(grad, grad_data.data(), 0, ggml_nbytes(grad));
        
        // SGDæ›´æ–°ï¼šparam = param - learning_rate * grad
        for (size_t i = 0; i < param_size; ++i) {
            param_data[i] -= learning_rate * grad_data[i];
        }
        
        // å†™å›æ›´æ–°åçš„å‚æ•°
        ggml_backend_tensor_set(param, param_data.data(), 0, ggml_nbytes(param));
    }
};

// ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼ˆXORé—®é¢˜ï¼‰
std::pair<std::vector<std::vector<float>>, std::vector<std::vector<float>>> generateXORData(int batch_size) {
    std::vector<std::vector<float>> X(batch_size, std::vector<float>(2));
    std::vector<std::vector<float>> y(batch_size, std::vector<float>(1));
    
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution<> dis(0, 3);
    
    for (int i = 0; i < batch_size; ++i) {
        int pattern = dis(gen);
        switch (pattern) {
            case 0: X[i] = {0.0f, 0.0f}; y[i] = {0.0f}; break;
            case 1: X[i] = {0.0f, 1.0f}; y[i] = {1.0f}; break;
            case 2: X[i] = {1.0f, 0.0f}; y[i] = {1.0f}; break;
            case 3: X[i] = {1.0f, 1.0f}; y[i] = {0.0f}; break;
        }
    }
    
    return {X, y};
}

int main() {
    std::cout << "ğŸš€ GGMLå¤šå±‚é€»è¾‘å›å½’æ¼”ç¤º\n";
    std::cout << "===============================\n\n";
    
    // ç½‘ç»œå‚æ•°
    const int input_size = 2;
    const int hidden_size = 8;
    const int output_size = 1;
    const int batch_size = 4;
    const int epochs = 1000;
    const float learning_rate = 0.1f;
    
    std::cout << "ç½‘ç»œç»“æ„: " << input_size << " â†’ " << hidden_size << " â†’ " << output_size << "\n";
    std::cout << "é—®é¢˜: XORé€»è¾‘å›å½’\n";
    std::cout << "æ‰¹å¤§å°: " << batch_size << "\n";
    std::cout << "è®­ç»ƒè½®æ•°: " << epochs << "\n\n";
    
    // åˆ›å»ºæ¨¡å‹
    GGMLMultiLayerLogisticRegression model(input_size, hidden_size, output_size, batch_size);
    
    // è®­ç»ƒ
    std::cout << "å¼€å§‹è®­ç»ƒ...\n";
    for (int epoch = 0; epoch < epochs; ++epoch) {
        auto [X, y] = generateXORData(batch_size);
        
        model.trainStep(X, y, learning_rate);
        
        if (epoch % 100 == 0 || epoch == epochs - 1) {
            float loss = model.forward(X, y);
            std::cout << "Epoch " << std::setw(4) << epoch << " | Loss: " << std::fixed << std::setprecision(6) << loss << "\n";
        }
    }
    
    // æµ‹è¯•
    std::cout << "\næµ‹è¯•ç»“æœ:\n";
    std::cout << "è¾“å…¥ â†’ è¾“å‡º (æœŸæœ›)\n";
    std::cout << "-------------------\n";
    
    std::vector<std::vector<float>> test_cases = {
        {0.0f, 0.0f}, {0.0f, 1.0f}, {1.0f, 0.0f}, {1.0f, 1.0f}
    };
    std::vector<float> expected = {0.0f, 1.0f, 1.0f, 0.0f};
    
    for (int i = 0; i < 4; ++i) {
        std::vector<std::vector<float>> X_test(batch_size, test_cases[i]);
        std::vector<std::vector<float>> y_dummy(batch_size, std::vector<float>(1, 0.0f));
        
        auto predictions = model.predict(X_test);
        float pred = predictions[0][0];
        
        std::cout << "(" << test_cases[i][0] << ", " << test_cases[i][1] << ") â†’ " 
                  << std::fixed << std::setprecision(3) << pred 
                  << " (" << expected[i] << ")" 
                  << (std::abs(pred - expected[i]) < 0.5 ? " âœ“" : " âœ—") << "\n";
    }
    
    std::cout << "\nâœ… æ¼”ç¤ºå®Œæˆï¼è¿™ä¸ªå¤šå±‚é€»è¾‘å›å½’å®Œå…¨ä½¿ç”¨GGMLå†…ç½®å‡½æ•°å®ç°ã€‚\n";
    std::cout << "ğŸ”§ ä½¿ç”¨çš„GGMLå‡½æ•°:\n";
    std::cout << "   - ggml_mul_mat() - çŸ©é˜µä¹˜æ³•\n";
    std::cout << "   - ggml_add() - åŠ æ³•\n";
    std::cout << "   - ggml_unary(RELU/SIGMOID) - æ¿€æ´»å‡½æ•°\n";
    std::cout << "   - ggml_cross_entropy_loss() - æŸå¤±å‡½æ•°\n";
    std::cout << "   - ggml_build_backward_expand() - è‡ªåŠ¨å¾®åˆ†\n";
    std::cout << "   - ggml_backend_graph_compute() - å›¾æ‰§è¡Œ\n";
    
    return 0;
} 