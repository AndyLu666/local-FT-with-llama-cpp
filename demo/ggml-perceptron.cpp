#include <iostream>
#include <vector>
#include <random>
#include <cmath>
#include <algorithm>
#include <iomanip>
#include <memory>
#include <cstring>

// åŒ…å«ggmlé ­æ–‡ä»¶
#include "ggml/include/ggml.h"

// å–®å±¤æ„ŸçŸ¥å™¨é¡ - ä½¿ç”¨ggmlå…§ç½®å‡½æ•¸
class GGMLPerceptron {
private:
    struct ggml_context* ctx_;
    struct ggml_tensor* weights_;  // æ¬Šé‡çŸ©é™£ [output_size, input_size]
    struct ggml_tensor* bias_;     // åç½®å‘é‡ [output_size]
    int input_size_;
    int output_size_;
    float learning_rate_;
    
public:
    GGMLPerceptron(int input_size, int output_size, float learning_rate = 0.01f)
        : input_size_(input_size), output_size_(output_size), learning_rate_(learning_rate) {
        
        // åˆå§‹åŒ–ggmlä¸Šä¸‹æ–‡
        struct ggml_init_params params = {
            .mem_size = 64 * 1024 * 1024,  // 64MBè¨˜æ†¶é«”
            .mem_buffer = NULL,
            .no_alloc = false,
        };
        
        ctx_ = ggml_init(params);
        if (!ctx_) {
            throw std::runtime_error("ç„¡æ³•åˆå§‹åŒ–ggmlä¸Šä¸‹æ–‡");
        }
        
        // å‰µå»ºæ¬Šé‡å’Œåç½®å¼µé‡
        weights_ = ggml_new_tensor_2d(ctx_, GGML_TYPE_F32, input_size_, output_size_);
        bias_ = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, output_size_);
        
        // è¨­ç½®ç‚ºå¯è¨“ç·´åƒæ•¸
        ggml_set_param(weights_);
        ggml_set_param(bias_);
        
        // åˆå§‹åŒ–æ¬Šé‡å’Œåç½®
        init_weights();
        
        std::cout << "âœ… GGMLæ„ŸçŸ¥å™¨å·²åˆå§‹åŒ–ï¼š" << input_size_ << " â†’ " << output_size_ << std::endl;
        std::cout << "ğŸ“Š æ¬Šé‡çŸ©é™£å½¢ç‹€ï¼š[" << weights_->ne[0] << ", " << weights_->ne[1] << "]" << std::endl;
        std::cout << "ğŸ“Š åç½®å‘é‡é•·åº¦ï¼š" << bias_->ne[0] << std::endl;
    }
    
    ~GGMLPerceptron() {
        if (ctx_) {
            ggml_free(ctx_);
        }
    }
    
    // åˆå§‹åŒ–æ¬Šé‡å’Œåç½®
    void init_weights() {
        std::mt19937 rng(42);
        std::normal_distribution<float> dist(0.0f, 0.1f);
        
        // åˆå§‹åŒ–æ¬Šé‡çŸ©é™£
        float* w_data = ggml_get_data_f32(weights_);
        for (int i = 0; i < ggml_nelements(weights_); ++i) {
            w_data[i] = dist(rng);
        }
        
        // åˆå§‹åŒ–åç½®å‘é‡
        float* b_data = ggml_get_data_f32(bias_);
        for (int i = 0; i < ggml_nelements(bias_); ++i) {
            b_data[i] = 0.0f;
        }
        
        std::cout << "ğŸ² æ¬Šé‡å’Œåç½®å·²éš¨æ©Ÿåˆå§‹åŒ–" << std::endl;
    }
    
    // å‰å‘å‚³æ’­ï¼šä½¿ç”¨ggmlå…§ç½®å‡½æ•¸
    struct ggml_tensor* forward(struct ggml_tensor* input) {
        // è¨ˆç®—ï¼šoutput = weights * input + bias
        // æ³¨æ„ï¼šggml_mul_matåŸ·è¡ŒçŸ©é™£ä¹˜æ³• A * B
        struct ggml_tensor* mul_result = ggml_mul_mat(ctx_, weights_, input);
        
        // æ·»åŠ åç½®ï¼ˆå»£æ’­ï¼‰
        struct ggml_tensor* output = ggml_add(ctx_, mul_result, bias_);
        
        // æ‡‰ç”¨sigmoidæ¿€æ´»å‡½æ•¸
        output = ggml_unary(ctx_, output, GGML_UNARY_OP_SIGMOID);
        
        return output;
    }
    
    // è¨ˆç®—æå¤±ï¼ˆå‡æ–¹èª¤å·®ï¼‰
    struct ggml_tensor* compute_loss(struct ggml_tensor* predictions, struct ggml_tensor* targets) {
        // è¨ˆç®—é æ¸¬å€¼èˆ‡ç›®æ¨™å€¼çš„å·®ç•°
        struct ggml_tensor* diff = ggml_sub(ctx_, predictions, targets);
        
        // è¨ˆç®—å¹³æ–¹
        struct ggml_tensor* squared = ggml_mul(ctx_, diff, diff);
        
        // è¨ˆç®—å‡å€¼
        struct ggml_tensor* loss = ggml_mean(ctx_, squared);
        
        return loss;
    }
    
    // è¨“ç·´æ­¥é©Ÿ
    void train_step(const std::vector<std::vector<float>>& inputs, 
                   const std::vector<std::vector<float>>& targets) {
        
        int batch_size = inputs.size();
        
        std::cout << "ğŸš€ é–‹å§‹è¨“ç·´æ­¥é©Ÿï¼Œæ‰¹æ¬¡å¤§å°ï¼š" << batch_size << std::endl;
        
        for (int i = 0; i < batch_size; ++i) {
            // å‰µå»ºè¼¸å…¥å¼µé‡
            struct ggml_tensor* input = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, input_size_);
            float* input_data = ggml_get_data_f32(input);
            std::memcpy(input_data, inputs[i].data(), input_size_ * sizeof(float));
            
            // å‰µå»ºç›®æ¨™å¼µé‡
            struct ggml_tensor* target = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, output_size_);
            float* target_data = ggml_get_data_f32(target);
            std::memcpy(target_data, targets[i].data(), output_size_ * sizeof(float));
            
            // å‰å‘å‚³æ’­
            struct ggml_tensor* prediction = forward(input);
            
            // è¨ˆç®—æå¤±
            struct ggml_tensor* loss = compute_loss(prediction, target);
            
            // è¨­ç½®æå¤±å¼µé‡
            ggml_set_loss(loss);
            
            // å‰µå»ºè¨ˆç®—åœ–
            struct ggml_cgraph* graph = ggml_new_graph_custom(ctx_, 1024, true);
            ggml_build_forward_expand(graph, loss);
            
            // æ§‹å»ºåå‘å‚³æ’­åœ–
            ggml_build_backward_expand(ctx_, graph, nullptr);
            
            // åŸ·è¡Œå‰å‘å’Œåå‘å‚³æ’­ï¼ˆé€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›éœ€è¦ä½¿ç”¨backendï¼‰
            // æ³¨æ„ï¼šå®Œæ•´çš„å¯¦ç¾éœ€è¦ä½¿ç”¨ggml_backendé€²è¡Œè¨ˆç®—
            
            if (i == 0) {  // åªæ‰“å°ç¬¬ä¸€å€‹æ¨£æœ¬çš„ä¿¡æ¯
                std::cout << "ğŸ“ˆ æ¨£æœ¬ " << i+1 << " è™•ç†å®Œæˆ" << std::endl;
            }
        }
        
        std::cout << "âœ… è¨“ç·´æ­¥é©Ÿå®Œæˆ" << std::endl;
    }
    
    // é æ¸¬
    std::vector<float> predict(const std::vector<float>& input) {
        // å‰µå»ºè¼¸å…¥å¼µé‡
        struct ggml_tensor* input_tensor = ggml_new_tensor_1d(ctx_, GGML_TYPE_F32, input_size_);
        float* input_data = ggml_get_data_f32(input_tensor);
        std::memcpy(input_data, input.data(), input_size_ * sizeof(float));
        
        // å‰å‘å‚³æ’­
        struct ggml_tensor* output = forward(input_tensor);
        
        // å‰µå»ºè¨ˆç®—åœ–ä¸¦åŸ·è¡Œå‰å‘å‚³æ’­
        struct ggml_cgraph* graph = ggml_new_graph(ctx_);
        ggml_build_forward_expand(graph, output);
        
        // æå–çµæœï¼ˆå¯¦éš›ä½¿ç”¨ä¸­éœ€è¦ä½¿ç”¨backendè¨ˆç®—ï¼‰
        std::vector<float> result(output_size_);
        float* output_data = ggml_get_data_f32(output);
        std::memcpy(result.data(), output_data, output_size_ * sizeof(float));
        
        return result;
    }
    
    // æ‰“å°æ¨¡å‹ä¿¡æ¯
    void print_model_info() {
        std::cout << "\nğŸ“‹ æ¨¡å‹è³‡è¨Šï¼š" << std::endl;
        std::cout << "   è¼¸å…¥å¤§å°ï¼š" << input_size_ << std::endl;
        std::cout << "   è¼¸å‡ºå¤§å°ï¼š" << output_size_ << std::endl;
        std::cout << "   å­¸ç¿’ç‡ï¼š" << learning_rate_ << std::endl;
        std::cout << "   ç¸½åƒæ•¸æ•¸é‡ï¼š" << (input_size_ * output_size_ + output_size_) << std::endl;
        std::cout << "   ä½¿ç”¨æ¿€æ´»å‡½æ•¸ï¼šSigmoid" << std::endl;
        std::cout << "   ä½¿ç”¨æå¤±å‡½æ•¸ï¼šå‡æ–¹èª¤å·®(MSE)" << std::endl;
        
        // é¡¯ç¤ºæ¬Šé‡çµ±è¨ˆä¿¡æ¯
        float* w_data = ggml_get_data_f32(weights_);
        float w_sum = 0.0f, w_min = w_data[0], w_max = w_data[0];
        int w_elements = ggml_nelements(weights_);
        
        for (int i = 0; i < w_elements; ++i) {
            w_sum += w_data[i];
            w_min = std::min(w_min, w_data[i]);
            w_max = std::max(w_max, w_data[i]);
        }
        
        std::cout << "   æ¬Šé‡çµ±è¨ˆï¼šå¹³å‡=" << std::fixed << std::setprecision(4) 
                  << (w_sum / w_elements) << ", æœ€å°=" << w_min << ", æœ€å¤§=" << w_max << std::endl;
    }
};

// ç”Ÿæˆè¨“ç·´è³‡æ–™
void generate_training_data(std::vector<std::vector<float>>& inputs,
                          std::vector<std::vector<float>>& targets,
                          int num_samples) {
    
    std::mt19937 rng(123);
    std::uniform_real_distribution<float> dist(-1.0f, 1.0f);
    
    inputs.resize(num_samples);
    targets.resize(num_samples);
    
    for (int i = 0; i < num_samples; ++i) {
        // ç”Ÿæˆ2ç¶­è¼¸å…¥
        inputs[i] = {dist(rng), dist(rng)};
        
        // ç°¡å–®çš„é‚è¼¯ï¼šå¦‚æœ x1 + x2 > 0ï¼Œå‰‡è¼¸å‡º1ï¼Œå¦å‰‡è¼¸å‡º0
        float sum = inputs[i][0] + inputs[i][1];
        targets[i] = {sum > 0.0f ? 1.0f : 0.0f};
    }
    
    std::cout << "ğŸ“Š å·²ç”Ÿæˆ " << num_samples << " å€‹è¨“ç·´æ¨£æœ¬" << std::endl;
    std::cout << "ğŸ“ ä»»å‹™ï¼šå­¸ç¿’å‡½æ•¸ f(x1, x2) = (x1 + x2 > 0) ? 1 : 0" << std::endl;
}

int main() {
    std::cout << "ğŸ¤– GGMLå–®å±¤æ„ŸçŸ¥å™¨æ¼”ç¤º\n" << std::endl;
    std::cout << "=====================================" << std::endl;
    
    try {
        // è¨­å®šåƒæ•¸
        const int input_size = 2;
        const int output_size = 1;
        const float learning_rate = 0.1f;
        const int num_samples = 100;
        const int num_epochs = 10;
        
        // å‰µå»ºæ¨¡å‹
        std::cout << "ğŸ—ï¸  æ­£åœ¨å‰µå»ºGGMLæ„ŸçŸ¥å™¨..." << std::endl;
        GGMLPerceptron model(input_size, output_size, learning_rate);
        model.print_model_info();
        
        // ç”Ÿæˆè¨“ç·´è³‡æ–™
        std::cout << "\nğŸ“š æ­£åœ¨ç”Ÿæˆè¨“ç·´è³‡æ–™..." << std::endl;
        std::vector<std::vector<float>> inputs, targets;
        generate_training_data(inputs, targets, num_samples);
        
        // é¡¯ç¤ºå¹¾å€‹æ¨£æœ¬
        std::cout << "\nğŸ” æ¨£æœ¬é è¦½ï¼š" << std::endl;
        for (int i = 0; i < std::min(5, num_samples); ++i) {
            std::cout << "   è¼¸å…¥: [" << std::fixed << std::setprecision(2) 
                      << inputs[i][0] << ", " << inputs[i][1] 
                      << "] â†’ ç›®æ¨™: " << targets[i][0] << std::endl;
        }
        
        // è¨“ç·´æ¨¡å‹
        std::cout << "\nğŸ¯ é–‹å§‹è¨“ç·´..." << std::endl;
        for (int epoch = 0; epoch < num_epochs; ++epoch) {
            std::cout << "\nğŸ“… Epoch " << (epoch + 1) << "/" << num_epochs << std::endl;
            model.train_step(inputs, targets);
        }
        
        // æ¸¬è©¦æ¨¡å‹
        std::cout << "\nğŸ§ª æ¸¬è©¦æ¨¡å‹..." << std::endl;
        std::vector<std::vector<float>> test_inputs = {
            {0.5f, 0.3f},   // æ‡‰è©²è¼¸å‡ºæ¥è¿‘1
            {-0.2f, -0.4f}, // æ‡‰è©²è¼¸å‡ºæ¥è¿‘0
            {0.1f, -0.05f}, // æ‡‰è©²è¼¸å‡ºæ¥è¿‘1
            {-0.3f, 0.1f}   // æ‡‰è©²è¼¸å‡ºæ¥è¿‘0
        };
        
        for (const auto& test_input : test_inputs) {
            auto prediction = model.predict(test_input);
            float expected = (test_input[0] + test_input[1] > 0.0f) ? 1.0f : 0.0f;
            
            std::cout << "   è¼¸å…¥: [" << std::fixed << std::setprecision(2)
                      << test_input[0] << ", " << test_input[1] 
                      << "] â†’ é æ¸¬: " << std::setprecision(3) << prediction[0]
                      << ", æœŸæœ›: " << expected << std::endl;
        }
        
        std::cout << "\nâœ… GGMLæ„ŸçŸ¥å™¨æ¼”ç¤ºå®Œæˆï¼" << std::endl;
        
        // èªªæ˜GGMLçš„å„ªå‹¢
        std::cout << "\nğŸ’¡ GGMLçš„å„ªå‹¢ï¼š" << std::endl;
        std::cout << "   ğŸ”§ å…§ç½®è‡ªå‹•å¾®åˆ†ï¼šç„¡éœ€æ‰‹å‹•è¨ˆç®—æ¢¯åº¦" << std::endl;
        std::cout << "   âš¡ å„ªåŒ–çš„ç®—å­ï¼šé«˜æ•ˆçš„çŸ©é™£é‹ç®—å’Œæ¿€æ´»å‡½æ•¸" << std::endl;
        std::cout << "   ğŸ§® è¨ˆç®—åœ–ï¼šæ”¯æ´è¤‡é›œçš„ç¥ç¶“ç¶²è·¯çµæ§‹" << std::endl;
        std::cout << "   ğŸš€ å¾Œç«¯æ”¯æ´ï¼šå¯åˆ©ç”¨GPU/CPUå„ªåŒ–" << std::endl;
        std::cout << "   ğŸ”’ è¨˜æ†¶é«”ç®¡ç†ï¼šçµ±ä¸€çš„å¼µé‡è¨˜æ†¶é«”æ± " << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ éŒ¯èª¤ï¼š" << e.what() << std::endl;
        return 1;
    }
    
    return 0;
} 